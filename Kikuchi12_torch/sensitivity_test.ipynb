{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data):\n",
    "  data_mean = np.mean(data, axis=0)\n",
    "  data_std  = np.std(data, axis=0)\n",
    "  data_norm = (data - data_mean) / data_std\n",
    "  data_norm = np.nan_to_num(data_norm, nan=0) # 欠損値(nan)を0で置換\n",
    "  del data_mean, data_std\n",
    "  return data_norm\n",
    "\n",
    "def indexing(lead_time):\n",
    "  output_shape = 2\n",
    "  rt = real_time2[:-lead_time-1]\n",
    "  t_data = PC_norm[lead_time:]\n",
    "  print(t_data.shape)\n",
    "  idx = np.where((rt.year <= 2015))[0]\n",
    "  t_train = t_data[idx]\n",
    "  idx = np.where((rt.year > 2015))[0]\n",
    "  t_test = t_data[idx]\n",
    "  print('t_train, t_test =', t_train.shape, t_test.shape)\n",
    "  return rt, t_train, t_test, output_shape\n",
    "\n",
    "def preprocess(data, rt, lead_time):\n",
    "  ipt_lag0  = data[10:-lead_time-1]\n",
    "  ipt_lag5  = data[5:-lead_time-6]\n",
    "  ipt_lag10 = data[:-lead_time-11]\n",
    "  # =========\n",
    "  # 検証データのみ\n",
    "  idx2 = np.where((rt.year > 2015))[0]\n",
    "  ipt_lag0_test = ipt_lag0[idx2]\n",
    "  ipt_lag5_test = ipt_lag5[idx2]\n",
    "  ipt_lag10_test = ipt_lag10[idx2]\n",
    "  ipt_test = np.stack([ipt_lag0_test, ipt_lag5_test, ipt_lag10_test], 3)\n",
    "  return ipt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def culc_cor(predict, y_test, lead_time):\n",
    "  cor = (np.sum(predict[:,0] * y_test[:,0], axis=0) + np.sum(predict[:,1] * y_test[:,1], axis=0)) / \\\n",
    "          (np.sqrt(np.sum(predict[:,0] ** 2 + predict[:,1] ** 2, axis=0)) * np.sqrt(np.sum(y_test[:,0] ** 2 + y_test[:,1] ** 2, axis=0)))\n",
    "  print('lead time {} day = '.format(lead_time), cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88988/730915222.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  data_norm = (data - data_mean) / data_std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_n =  (15991, 25, 144, 8)\n",
      "PCs =  (15981, 2)\n",
      "time PCs=  (15981,)\n",
      "real time PCs =  1979-04-01 00:00:00 2022-12-31 00:00:00\n",
      "==== lead time : 0 day =====\n",
      "(15981, 2)\n",
      "t_train, t_test = (13424, 2) (2556, 2)\n",
      "rt, t_train, t_test =  (15980,) (13424, 2) (2556, 2)\n",
      "x_test = (2556, 24, 25, 144)\n",
      "(15981, 2)\n",
      "t_train, t_test = (13424, 2) (2556, 2)\n",
      "rt, t_train, t_test = (15980,) (13424, 2) (2556, 2)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/maeda/machine_learning/results/model/kikuchi-8vals_v1/8vals/model_000day/seed000.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m rt, t_train, t_test, output_shape \u001b[38;5;241m=\u001b[39m indexing(lead_time)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrt, t_train, t_test =\u001b[39m\u001b[38;5;124m'\u001b[39m, rt\u001b[38;5;241m.\u001b[39mshape, t_train\u001b[38;5;241m.\u001b[39mshape, t_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 77\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/maeda/machine_learning/results/model/kikuchi-8vals_v1/8vals/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(lead_time)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mday/seed\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(seed_box[lead_time])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m     79\u001b[0m x_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(x_test)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/torch/serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/torch/serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/torch/serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/maeda/machine_learning/results/model/kikuchi-8vals_v1/8vals/model_000day/seed000.pth'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  \n",
    "  #mode = 'mjo'\n",
    "  mode = 'bsiso'\n",
    "  data = np.load('/home/maeda/data/bsiso_eeof/prepro_anomaly_8vals.npz')\n",
    "\n",
    "  olr = data['olr'][80:,24:49,:]\n",
    "  u850 = data['u850'][80:,24:49,:]\n",
    "  v850 = data['v850'][80:,24:49,:]\n",
    "  u200 = data['u200'][80:,24:49,:]\n",
    "  v200 = data['v200'][80:,24:49,:]\n",
    "  h850 = data['h850'][80:,24:49,:]\n",
    "  pr_wtr = data['pr_wtr'][80:,24:49,:]\n",
    "  sst = data['sst'][80:,24:49,:]\n",
    "\n",
    "  lat = data['lat'][24:49]\n",
    "  lon = data['lon']\n",
    "  time = data['time'][80:]    # 射影後にデータが10日進むため、時刻の方を前進させておく\n",
    "  real_time = pd.to_datetime(time, unit='h', origin=pd.Timestamp('1800-01-01')) # 時刻をdatetime型に変換\n",
    "\n",
    "  x = np.stack([olr, u850, v850, u200, v200, h850, pr_wtr, sst], 3)\n",
    "  x_n = np.zeros(x.shape)\n",
    "  for i in range(x.shape[3]):\n",
    "    x_n[:,:,:,i] = normalization(x[:,:,:,i])\n",
    "  print('x_n = ', x_n.shape)  \n",
    "  x_test = []\n",
    "\n",
    "  # bsiso index (eEOF) 読み込み\n",
    "  if mode == 'bsiso':\n",
    "    data_file = '/home/maeda/data/bsiso_eeof/bsiso_rt-PCs.npz'\n",
    "  elif mode == 'mjo':\n",
    "    data_file = '/home/maeda/data/bsiso_eeof/mjo_rt-PCs.npz'\n",
    "  PC      = np.load(data_file)['rt_PCs'][:,:2]\n",
    "  sign    = np.array([-1, 1]).T\n",
    "  PC_norm = sign * PC / PC.std(axis=0)[np.newaxis,:]\n",
    "  time2   = np.load(data_file)['time']\n",
    "  real_time2 = pd.to_datetime(time2, unit='h', origin=pd.Timestamp('1800-01-01')) # 時刻をdatetime型に変換\n",
    "  print('PCs = ', PC_norm.shape)\n",
    "  print('time PCs= ', time2.shape)\n",
    "  print('real time PCs = ', real_time2[0], real_time2[-1])\n",
    "\n",
    "  def test_step(x, t):\n",
    "    model.eval()\n",
    "    preds = model(x)\n",
    "    loss = loss_fn(preds, t)\n",
    "    return loss, preds\n",
    "  \n",
    "\n",
    "  #lt_box = [0, 5, 10, 15, 20, 25, 30, 35]\n",
    "  lt_box = np.arange(0, 36, 1)\n",
    "  seed_box = [0, 7, 7, 9, 5, 1, 2, 1, 1, 8, \n",
    "              5, 1, 1, 0, 5, 3, 3, 4, 5, 2,\n",
    "              3, 3, 3, 5, 5, 6, 6, 7, 2, 6,\n",
    "              5]\n",
    "  \n",
    "  for lead_time in lt_box:\n",
    "    print('==== lead time : {} day ====='.format(lead_time))\n",
    "    # answer data\n",
    "    rt, t_train, t_test, output_shape = indexing(lead_time)\n",
    "    print('rt, t_train, t_test = ', rt.shape, t_train.shape, t_test.shape)\n",
    "    # input data\n",
    "    x_test = []\n",
    "    for i in range(8):\n",
    "      _x_test = preprocess(x_n[:,:,:,i], rt, lead_time)\n",
    "      x_test.append(_x_test)\n",
    "    x_test = np.stack(np.array(x_test), 3).reshape(-1, 25, 144, 8*3).transpose(0, 3, 1, 2)\n",
    "    print('x_test =', x_test.shape)\n",
    "    rt, t_train, t_test, output_shape = indexing(lead_time)\n",
    "    print('rt, t_train, t_test =', rt.shape, t_train.shape, t_test.shape)\n",
    "    \n",
    "    model = torch.load(f'/home/maeda/machine_learning/results/model/kikuchi-8vals_v1/8vals/model_{(lead_time):03}day/seed{(seed_box[lead_time]):03}.pth')\n",
    "    loss_fn = nn.MSELoss()\n",
    "    x_test = torch.Tensor(x_test).to(device)\n",
    "    t_test = torch.Tensor(t_test).to(device)\n",
    "    test_loss, preds_test = test_step(x_test, t_test)\n",
    "    print('test loss: {:.3}'.format(\n",
    "      test_loss.item()\n",
    "      ))  \n",
    " \n",
    "    predict = preds_test.cpu().detach().numpy()\n",
    "    t_test  = t_test.cpu().detach().numpy()\n",
    "    print(predict.shape)\n",
    "      \n",
    "    culc_cor(predict, t_test, lead_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
